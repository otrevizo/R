---
title: 'CSCI E-63C: Week 1 Q&A session'
output:
  html_document:
    toc: true
---

```{r setup, include=TRUE}
library(ISLR)
library(RColorBrewer)
library(reshape2)
library(ggplot2)
knitr::opts_chunk$set(echo = TRUE)
```

# Install R

Available at https://www.r-project.org/

# Install Rstudio

Available at https://www.rstudio.com/

# Install packages

ISLR, ggplot2, reshape2, RColorBrewer

# "Knit HTML"

* Just a button in Rstudio
* Good starting point is "File->New File->R Markdown...", follow prompts and then "Knit HTML"

# Homework and quiz

* 60 points for coding assignment, 40 points for quiz
* here we'll review the main points of coding assignment
* quiz is designed to prompt review of the lecture / suggested reading
  + if you find yourself googling, you must be overthinking it
  + reach out on piazza (as a private question if your prefer)
  + *SIGN-UP TO PIAZZA IF YOU HAVEN'T YET*
* midterm and final exams will be also take home week long data analysis projects
  + no quiz as part of midterm/final

# Q&A topics

* How to ...?
* How come R ...?
* Why statistical learning ...?
* `?help` vs `help` vs `help()`
* "An Introduction to R" by `help.start()`
* Google
* O'Reilly "R cookbook" by Paul Teetor
* http://www.nytimes.com/2009/01/07/technology/business-computing/07program.html (NYT version)
* http://arrgh.tim-smith.us/ (some cathartic reading for those who programmed in other languages):
    + "R is a shockingly dreadful language for an exceptionally useful data analysis environment"


# R caveats

* R assumes for you a lot
* converts types for you
* type checking
* Rather than "if it compiles, it works", "if it works, still check the results", 
* factors!!! 
* What can be worse than global variables?  ".RData", of course!
* `save()` computationally expensive results
* plenty of others...


# Some of the good practices

* literate programming/reproducible research (knitr, sweave, rstudio) 
* paying attention to warnings, building gradually, testing all along
* more efficient when vectorized, simulation in a matrix
* there are profiling tools (e.g. http://adv-r.had.co.nz/Profiling.html), but then remember Donald Knuth's view on premature optimization
* Use functions: they promote code reuse and help cutting down on global variables

# Example of the effect of vectorization

```{r vectperf}
x <- matrix(rnorm(50000*10),ncol=10)
y <- numeric(); pt1 <- proc.time()
for ( i in 1:dim(x)[1] ) y[i] <- mean(x[i,])
pt2 <- proc.time(); pt2-pt1; y[1:3]
y <- apply(x,1,mean)
pt3 <- proc.time(); pt3 - pt2; y[1:3]
y <- rowMeans(x)
proc.time() - pt3; y[1:3]
```

# Plots from ISLR Ch. 1

## Plots from Fig.1.1

```{r wageplots,fig.width=9,fig.height=5}
class(Wage)
dim(Wage)
nrow(Wage)
ncol(Wage)
head(Wage)
old.par <- par(mfrow=c(1,3),ps=16)
plot(Wage[,c("age","wage")],xlab="Age",ylab="Wage",pch=20,col="gray")
points(min(Wage$age):max(Wage$age),predict(loess(wage~age,Wage),newdata=data.frame(age=min(Wage$age):max(Wage$age))),col="blue",type="l",lwd=2)
plot(Wage[,c("year","wage")],xlab="Year",ylab="Wage",pch=20,col="gray")
abline(lm(wage~year,Wage),col="blue",lwd=2)
boxplot(wage~substring(education,1,1),Wage,col=brewer.pal(5,"Dark2"),xlab="Education Level",ylab="Wage")  #YlGnBu RdYlGn Accent
par(old.par)
```

## Plots from Fig.1.2

```{r fig12plots,echo=FALSE,fig.width=9,fig.height=5}
class(Smarket)
dim(Smarket)
summary(Smarket)
head(Smarket)
old.par <- par(mfrow=c(1,3),ps=16)
for ( tmpLag in 1:3 ) {
  boxplot(as.formula(paste0("Lag",tmpLag,"~Direction")),Smarket,ylab="Percentage change in S&P",xlab="Today's Direction",main=c("Yesterday","Two Days Previous","Three Days Previous")[tmpLag],col=c("skyblue2","darkorange3"))
}
par(old.par)
```

Similar plots by `ggplot`:

```{r fig12ggplots,fig.width=9,fig.height=5}
ggplot(melt(Smarket[,c("Direction",paste0("Lag",1:3))]),aes(x=Direction,y=value,fill=Direction))+geom_boxplot()+facet_wrap(~variable)+theme(legend.position="none")+xlab("Today's Direction")+ylab("Percentage change in S&P")
```


# More useful pointers / food for thought

* ["50 years of Data Science"](http://courses.csail.mit.edu/18.337/2015/docs/50YearsDataScience.pdf)
* ["Classifier Technology and the Illusion of Progress"](https://arxiv.org/pdf/math/0606441.pdf)
* ["Statistical Modeling: The Two Cultures"](https://projecteuclid.org/download/pdf_1/euclid.ss/1009213726)
* ["ASA statement on  p-values"](http://amstat.tandfonline.com/doi/full/10.1080/00031305.2016.1154108)
* [Replication crisis and reproducible research](http://simplystatistics.org/2016/08/24/replication-crisis/)
* Other examples of data analysis debacles: Duke chemosensitivity, etc.
* *"Essentially, all models are wrong, but some are useful"* **[George E. P. Box]**
* *"There is no true interpretation of anything; interpretation is a vehicle in the service of human comprehension. The value of interpretation is in enabling others to fruitfully think about an idea."* **[Andreas Buja]**